{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "search_engine_id = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"We are seeking a Lead Data Scientist with experience in various data science techniques, tools, and cloud providers. \\n \\n The ideal candidate will be responsible for designing, developing, and implementing cutting-edge data science models and machine learning algorithms to tackle complex problems in various domains. You will work closely with cross-functional teams to understand business requirements, identify opportunities for applying machine learning/deep learning/AI techniques, and deliver innovative solutions that push the boundaries of AI technology. This role requires a strong background in machine learning, deep learning, and computer vision, along with a passion for exploring and experimenting with state-of-the-art models. \\nResponsibilities Design, develop, and implement novel data science models and machine learning algorithms that solve complex problems. This includes architectural design, data preprocessing, training, optimization, and evaluation of models Collaborate with data engineers and data scientists to collect, pre-process, and curate datasets suitable for training Train and fine-tune machine learning/deep learning models using large-scale datasets and distributed computing frameworks. Optimize models for performance, efficiency, and scalability Design and conduct experiments to evaluate the performance, robustness, and generalization of tune machine learning/deep learning models Use appropriate metrics and statistical analysis to measure and interpret results Prepare technical documentation, including model architecture, implementation details, and experimental results. Communicate findings, insights, and recommendations to both technical and non-technical stakeholders RequirementsBachelor’s or master’s degree in computer science, Data Science, Statistics, or related field8 to 12 years of solid foundation in Machine Learning, Deep Learning, Computer Vision, NLP Proficiency in Python Experience Deep learning framework like Tensorflow, Pytorch, Keras, Jax, etc. Experience with pandas, scikit-learn, matplotlib, spacy, statsmodel, etc. General understanding of data structures, algorithms, multi-threaded programming, and distributed computing conceptsKnowledge of statistical and algorithmic models as well as of fundamental mathematical concepts, such as linear algebra and probabilityFamiliarity with cloud services (AWS, Google Cloud, Azure) Excellent written and verbal communication skills Good to have - Docker, Kubernetes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = \" Sanjay Lalwani Pune, India | +91-9175892998 | sanjay.lalwani3@gmail.com | linkedin.com/in/sanjaylalwani3/ https://www.youtube.com/@GenAiTalks | https://github.com/sanjaylalwani | https://medium.com/@sanjay-lalwani3 Skilled Data Scientist with 5+ years in data & AI, & 14+ years in Development. Proficient in Software development, data engineering, machine learning, deep learning, NLP, & cloud computing. Track record of successful project implementation under tight timelines. Adaptable & motivated team player. Projects & Experience Siemens, Pune, India— Data Scientist October 2022 - Present Ownership: Bot Evaluation Tool ● Developed a custom bot evaluation tool using Streamlit and Azure, leveraging the RAGAS framework to streamline bot testing and evaluation. ● Enabled automated evaluation for over 20 internal bots, significantly reducing testing eff orts. ● Integrated testing capabilities with OpenAI API and Azure Bot Framework endpoints, ensuring comprehensive bot performance analysis. ● This tool also helps to understand diff erent aspects of bot like Most frequent questions, answer success rate. Project: Business Smart Process & Governance Bot Tech used: Python, Langchain, Azure, OpenAI GPT-4 API, and MS Teams Role: Project Management and Development ● Led a chatbot project based on Azure & OpenAI, improving productivity by 12% by reducing the time taken to get accurate answers at diff erent locations. ● Bot helps improve current process management for our biggest business partner. ● Bot collects data from diff erent sources, tools, instructions, guidelines, and standards and acts as a single point of information. ● Managed timelines, budget, & resource allocation Agile based projects. ● Collaborated with cross-functional teams to identify insights. Project: Tier-N information entity extraction Tech used: Python, Langchain, Azure, OpenAI GPT-4 API, neo4j - GraphDb, Streamlit Role: Project Management and Development ● This application helps Supply Chain Management to improve transparency associated with diff erent manufacturers and raw materials, thus reducing the risks. ● The app extracts key information from diff erent manufacturer notifications. ● Graph databases help to keep diff erent tier information. Infosys Limited, Pune, India — Senior Lead Data Scientist March 2020 - September 2022 Project: Inventory prediction Tech used: Python,AWS, Time-Series ● Created data-driven action plans to increase profitability & reduce risk. ● Utilized Time-Series Analysis & Forecasting to achieve a 10% reduction in unsold inventory. ● Developed a K-means based system to cluster diff erent customers. ● Analyzed messy data, enhanced quality, delivered insights. ● Nurtured a high-trust environment with a collaborative environment. Infosys Limited, NewJersey, USA — Lead Data Scientist January 2018 - February 2020 Project: Recommendation Engine Tech used: Python,AWS ● Created item similarity program , resulting in a 5% sales surge. ● Promoted a data-driven decision-making culture & improved the customer recommendation engine. ● Performed data cleansing activities with pandas, ml algorithms. ● Developed data roadmap & evangelized analytic data vision. ● Built data ETL pipeline platforms using AWS S3, Glue, Lambda. Infosys Limited, NewJersey, USA— Technology Analyst July-2014 - December 2017 ● Developed Assortment planning tool, resulting in annual cost savings of $150k for the client. Worked on SSRS reports for data visualization. Infosys Limited, Mangalore, India — Senior System Engineer November 2010 - June 2014 ● Managed deliverables & mentored team members. Developed applications with C#.Net. IQSPL, Pune, India — Software Developer May 2009 - October 2010 ● Developed applications with C#, ASP.Net, SQL Server. Awards and Achievements ● Led GenAi-2023 Hackathon: We worked on 10 diff erent Siemens-Indian business team use cases for POC or Feasibility Analysis. ● STAR award Siemens 2023 : For remarkable dedication for multiple projects, and steering them in right directions. ● Insta Award, Infosys Limited, 2019 ● Bravo Award Ralph Lauren, 2018 : For hard work on ML based PFS buy tool, & continued support to align on the business initiatives, and strategies Presentations ● Guest Lecture: “Impact of Gen AI in Operations” at AutomationExpo-24 Talked about the crucial role of Generative AI in factory operations, focusing on lean processes and quality improvement. ● Generative AI Training – Siemens Business & Tech Teams Delivered introductory GenAI training for technical and functional teams, covering practical and functional insights. ● Analytics Vidhya’s The Data Hour Series (2023) Presented an in-depth session on LangChain, discussing its features and diverse capabilities. Skills ● Programming Languages: Python, C# ● Technical Skills: Machine Learning, Natural Language Processing, Data Analysis, MLOps ● Cloud Platform: AWS , Azure ● Generative AI: Azure OpenAI, Langchain, Azure AI Search ● Bot framework: MS Teams ● Version Control Service: Gitlab ● Libraries: OpenAI, Scikit-learn, Langchain, Datadogpy, Seaborn, spaCy, NLTK, MLFlow, Tensorflow, Keras, OpenCV Certifications ● Microsoft Azure Fundamentals Azure AI-900, 2023 ● Microsoft Azure AI Fundamentals Azure AZ-900, 2023 Education B.E. Computer, 2008 North Maharashtra University, Jalgaon with First Class \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    if not api_key or not search_engine_id:\n",
    "        raise ValueError(\"API key or Search Engine ID not found in environment variables\")\n",
    "\n",
    "    url = \"https://customsearch.googleapis.com/customsearch/v1\"\n",
    "    params = {\"key\": str(api_key), \"cx\": str(search_engine_id), \"q\": str(query), \"num\": str(num_results)}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"items\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item[\"snippet\"], \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    return enriched_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_jd_cv(ticker: str) -> dict:  # type: ignore[type-arg]\n",
    "    return jd + \" \" + cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")\n",
    "jd_analysis_tool = FunctionTool(analyze_jd_cv, description=\"Analyze job description data, my cv and select 2 matching questions from given list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o\"),\n",
    "    tools=[google_search_tool],\n",
    "    description=\"Search Google for information, returns top 2 results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")\n",
    "\n",
    "stock_analysis_agent = AssistantAgent(\n",
    "    name=\"Job_Description_Analysis_Agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o\"),\n",
    "    tools=[jd_analysis_tool],\n",
    "    description=\"Analyze stock data and generate a plot\",\n",
    "    system_message=\"You are a helpful assistant which takes list of questions, and job description, then maps most relevant 5 questions to job description.\",\n",
    ")\n",
    "\n",
    "\n",
    "report_agent = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o\"),\n",
    "    description=\"Take a role given, and generate a list of questions for the same\",\n",
    "    system_message=\"You are a helpful assistant that take top 2 questions from the list, and generate concise crisp answer for the interview. When you done with generating the report, reply with TERMINATE.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = RoundRobinGroupChat([stock_analysis_agent, search_agent, report_agent], max_turns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Give the list of questions for Senior Data Scientist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Job_Description_Analysis_Agent ----------\n",
      "Here is a list of questions that are typically asked for a Senior Data Scientist position:\n",
      "\n",
      "1. Can you describe your experience with machine learning algorithms? Which algorithms do you prefer and why?\n",
      "2. How do you handle missing data when preparing a dataset for machine learning?\n",
      "3. Describe a data science project you have worked on where you had a significant impact on the outcome.\n",
      "4. How do you ensure that your model is robust and does not overfit the training data?\n",
      "5. What experience do you have with big data technologies, such as Hadoop, Spark, or similar tools?\n",
      "6. Can you explain the concept of a recommendation system and your experience with developing one?\n",
      "7. How do you deal with data that is imbalanced, such as a dataset with many more negative samples than positive ones?\n",
      "8. What is your experience with deep learning frameworks like TensorFlow or PyTorch?\n",
      "9. Can you walk through your process for feature selection and why it's important?\n",
      "10. Describe a situation where you had to communicate complex data insights to a non-technical audience. How did you approach it?\n",
      "11. What is your experience with natural language processing (NLP)?\n",
      "12. How do you evaluate the performance of a predictive model?\n",
      "13. Have you ever made a mistake in a data analysis project? How did you handle it?\n",
      "14. What approaches do you use for hyperparameter tuning?\n",
      "15. How important is domain knowledge in your data science projects, and how do you acquire it?\n",
      "[Prompt tokens: 99, Completion tokens: 299]\n",
      "---------- Google_Search_Agent ----------\n",
      "If you need more specific or tailored questions based on a particular job description or company, please let me know, and I can assist you further!\n",
      "[Prompt tokens: 428, Completion tokens: 31]\n",
      "---------- Report_Agent ----------\n",
      "1. **Experience with Machine Learning Algorithms**:  \n",
      "   Senior data scientists are expected to have extensive experience with machine learning algorithms. This includes not only a familiarity with a wide range of algorithms but also an understanding of when each is applicable. Candidates should discuss their experiences with algorithms like decision trees, neural networks, random forests, and support vector machines. Preferences for particular algorithms might depend on factors like dataset size, the complexity of the problem, interpretability, and computational efficiency.\n",
      "\n",
      "2. **Project Impact**:  \n",
      "   Being able to articulate a data science project where you had a significant impact is crucial. Senior data scientists should demonstrate not just technical proficiency but also their ability to drive real business results. In describing a project, highlight the initial problem, the analytical approach taken, key insights gained, implementation of solutions, and the quantifiable impact it had on the business, such as improved KPIs, cost savings, or revenue growth.\n",
      "\n",
      "TERMINATE\n",
      "[Prompt tokens: 406, Completion tokens: 191]\n",
      "---------- Summary ----------\n",
      "Number of messages: 4\n",
      "Finish reason: Maximum number of turns 3 reached.\n",
      "Total prompt tokens: 933\n",
      "Total completion tokens: 521\n",
      "Duration: 10.73 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give the list of questions for Senior Data Scientist', type='TextMessage'), TextMessage(source='Job_Description_Analysis_Agent', models_usage=RequestUsage(prompt_tokens=99, completion_tokens=299), content=\"Here is a list of questions that are typically asked for a Senior Data Scientist position:\\n\\n1. Can you describe your experience with machine learning algorithms? Which algorithms do you prefer and why?\\n2. How do you handle missing data when preparing a dataset for machine learning?\\n3. Describe a data science project you have worked on where you had a significant impact on the outcome.\\n4. How do you ensure that your model is robust and does not overfit the training data?\\n5. What experience do you have with big data technologies, such as Hadoop, Spark, or similar tools?\\n6. Can you explain the concept of a recommendation system and your experience with developing one?\\n7. How do you deal with data that is imbalanced, such as a dataset with many more negative samples than positive ones?\\n8. What is your experience with deep learning frameworks like TensorFlow or PyTorch?\\n9. Can you walk through your process for feature selection and why it's important?\\n10. Describe a situation where you had to communicate complex data insights to a non-technical audience. How did you approach it?\\n11. What is your experience with natural language processing (NLP)?\\n12. How do you evaluate the performance of a predictive model?\\n13. Have you ever made a mistake in a data analysis project? How did you handle it?\\n14. What approaches do you use for hyperparameter tuning?\\n15. How important is domain knowledge in your data science projects, and how do you acquire it?\", type='TextMessage'), TextMessage(source='Google_Search_Agent', models_usage=RequestUsage(prompt_tokens=428, completion_tokens=31), content='If you need more specific or tailored questions based on a particular job description or company, please let me know, and I can assist you further!', type='TextMessage'), TextMessage(source='Report_Agent', models_usage=RequestUsage(prompt_tokens=406, completion_tokens=191), content='1. **Experience with Machine Learning Algorithms**:  \\n   Senior data scientists are expected to have extensive experience with machine learning algorithms. This includes not only a familiarity with a wide range of algorithms but also an understanding of when each is applicable. Candidates should discuss their experiences with algorithms like decision trees, neural networks, random forests, and support vector machines. Preferences for particular algorithms might depend on factors like dataset size, the complexity of the problem, interpretability, and computational efficiency.\\n\\n2. **Project Impact**:  \\n   Being able to articulate a data science project where you had a significant impact is crucial. Senior data scientists should demonstrate not just technical proficiency but also their ability to drive real business results. In describing a project, highlight the initial problem, the analytical approach taken, key insights gained, implementation of solutions, and the quantifiable impact it had on the business, such as improved KPIs, cost savings, or revenue growth.\\n\\nTERMINATE', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = team.run_stream(task=\"Give the list of questions for Senior Data Scientist\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TaskResult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTaskResult\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TaskResult' is not defined"
     ]
    }
   ],
   "source": [
    "TaskResult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_autogent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
